{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_feature = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_features.csv\")\n",
    "test_feature = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/test_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_targets_nonscored.csv\")\n",
    "sub = pd.read_csv('../../Data/Mechanisms of Action (MoA) Prediction/sample_submission.csv')\n",
    "data = train_feature.append(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data encoding\n",
    "def preprocess(df):\n",
    "#   df.loc[:,'cp_type'] =  df.loc[:,'cp_type'].map({'trt_cp' : 0,'ctl_vehicle' : 1})\n",
    "    df.drop(['cp_type'],axis=1,inplace=True)\n",
    "    df.loc[:,'cp_dose'] = df.loc[:,'cp_dose'].map({'D1':0,'D2':1})\n",
    "    df.loc[:,'cp_time'] = df.loc[:,'cp_time'].map({24:0,48:1,72:2})\n",
    "    df = pd.get_dummies(df,columns=['cp_dose','cp_time'])\n",
    "    del df['sig_id']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = preprocess(train_feature)\n",
    "test = preprocess(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler to train and test data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(train)\n",
    "\n",
    "train_transient = scaler.transform(train)\n",
    "test_transient = scaler.transform(test)\n",
    "\n",
    "train = pd.DataFrame(train_transient, columns=train.columns)\n",
    "test = pd.DataFrame(test_transient, columns=test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_targets_scored.drop(['sig_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(yt,yp):\n",
    "    return log_loss(yt, yp, eps=1e-15, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_input, activation='relu'):\n",
    "    model=tf.keras.Sequential()\n",
    "    model.add(L.Input(num_input))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(L.Dropout(0.2))\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(1024,activation = activation)))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(L.Dropout(0.2))\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(1024,activation = activation)))\n",
    "    model.add(L.BatchNormalization())\n",
    "    model.add(tfa.layers.WeightNormalization(L.Dense(206,activation = 'sigmoid')))\n",
    "    \n",
    "    model.compile(optimizer = tfa.optimizers.AdamW(lr=1e-3, weight_decay=1e-5\n",
    "                                                   ,clipvalue=786)\n",
    "                  , loss=BinaryCrossentropy(label_smoothing=1e-15))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top feats length: 877\n"
     ]
    }
   ],
   "source": [
    "# Use All feats as top feats\n",
    "top_feats = [i for i in range(train.shape[1])]\n",
    "print(\"Top feats length:\",len(top_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(y_true,y_pred):\n",
    "    metrics=[]\n",
    "    for _target in train_targets_scored.columns[1:]:\n",
    "        metrics.append(loss_fn(y_true.loc[:,_target],y_pred.loc[:,_target].astype(float)))\n",
    "        \n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128\n",
    "FOLDS = 5\n",
    "REPEATS = 1\n",
    "LR = 0.0005\n",
    "N_TARGETS = len(train_targets_scored.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train(resume_models=None, repeat_number=0, folds=5, skip_folds=0):\n",
    "    \n",
    "    models=[]\n",
    "    preds = y_train.copy()\n",
    "    \n",
    "    kfold = KFold(folds, shuffle=True)\n",
    "    for fold,(train_indices,val_indices) in enumerate(kfold.split(train)):\n",
    "        print('\\n')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold+1}')\n",
    "        print(fold)\n",
    "        cb_lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor = 'val_loss', factor = 0.4, patience = 2, \n",
    "            verbose = 1, min_delta = 0.0001, mode = 'auto')\n",
    "        \n",
    "        checkpoint_path = f'Repeat{repeat_number}_Fold{fold}.hdf5'\n",
    "        cb_checkpt = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                        monitor = 'val_loss', \n",
    "                                                        verbose = 0, \n",
    "                                                        save_best_only = True, \n",
    "                                                        save_weights_only = True, \n",
    "                                                        mode = 'min')\n",
    "        \n",
    "        model = create_model(len(top_feats))\n",
    "        model.fit(train.values[train_indices],\n",
    "              y_train.values[train_indices],\n",
    "              validation_data=(train.values[val_indices], y_train.values[val_indices]),\n",
    "              callbacks = [cb_lr_schedule, cb_checkpt],\n",
    "              epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2\n",
    "             )\n",
    "        \n",
    "        model.load_weights(checkpoint_path)\n",
    "        preds.loc[val_indices, :] = model.predict(train.values[val_indices])\n",
    "        models.append(model)\n",
    "        \n",
    "    return models,preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 1\n",
      "0\n",
      "Epoch 1/20\n",
      "149/149 - 11s - loss: 0.2779 - val_loss: 0.0391\n",
      "Epoch 2/20\n",
      "149/149 - 11s - loss: 0.0262 - val_loss: 0.0230\n",
      "Epoch 3/20\n",
      "149/149 - 11s - loss: 0.0194 - val_loss: 0.0193\n",
      "Epoch 4/20\n",
      "149/149 - 11s - loss: 0.0176 - val_loss: 0.0175\n",
      "Epoch 5/20\n",
      "149/149 - 11s - loss: 0.0166 - val_loss: 0.0165\n",
      "Epoch 6/20\n",
      "149/149 - 11s - loss: 0.0156 - val_loss: 0.0172\n",
      "Epoch 7/20\n",
      "149/149 - 11s - loss: 0.0150 - val_loss: 0.0160\n",
      "Epoch 8/20\n",
      "149/149 - 11s - loss: 0.0142 - val_loss: 0.0160\n",
      "Epoch 9/20\n",
      "149/149 - 11s - loss: 0.0135 - val_loss: 0.0158\n",
      "Epoch 10/20\n",
      "149/149 - 11s - loss: 0.0128 - val_loss: 0.0158\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "149/149 - 11s - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 12/20\n",
      "149/149 - 11s - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "149/149 - 11s - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 14/20\n",
      "149/149 - 11s - loss: 0.0086 - val_loss: 0.0159\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "149/149 - 11s - loss: 0.0083 - val_loss: 0.0159\n",
      "Epoch 16/20\n",
      "149/149 - 11s - loss: 0.0079 - val_loss: 0.0160\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "149/149 - 11s - loss: 0.0078 - val_loss: 0.0160\n",
      "Epoch 18/20\n",
      "149/149 - 11s - loss: 0.0076 - val_loss: 0.0160\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "149/149 - 11s - loss: 0.0076 - val_loss: 0.0160\n",
      "Epoch 20/20\n",
      "149/149 - 11s - loss: 0.0076 - val_loss: 0.0160\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 2\n",
      "1\n",
      "Epoch 1/20\n",
      "149/149 - 11s - loss: 0.2797 - val_loss: 0.0377\n",
      "Epoch 2/20\n",
      "149/149 - 11s - loss: 0.0268 - val_loss: 0.0238\n",
      "Epoch 3/20\n",
      "149/149 - 11s - loss: 0.0198 - val_loss: 0.0200\n",
      "Epoch 4/20\n",
      "149/149 - 11s - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 5/20\n",
      "149/149 - 11s - loss: 0.0165 - val_loss: 0.0169\n",
      "Epoch 6/20\n",
      "149/149 - 11s - loss: 0.0158 - val_loss: 0.0164\n",
      "Epoch 7/20\n",
      "149/149 - 11s - loss: 0.0150 - val_loss: 0.0163\n",
      "Epoch 8/20\n",
      "149/149 - 11s - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 9/20\n",
      "149/149 - 11s - loss: 0.0135 - val_loss: 0.0159\n",
      "Epoch 10/20\n",
      "149/149 - 11s - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "149/149 - 11s - loss: 0.0118 - val_loss: 0.0159\n",
      "Epoch 12/20\n",
      "149/149 - 11s - loss: 0.0103 - val_loss: 0.0159\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "149/149 - 11s - loss: 0.0095 - val_loss: 0.0160\n",
      "Epoch 14/20\n",
      "149/149 - 11s - loss: 0.0086 - val_loss: 0.0160\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "149/149 - 11s - loss: 0.0083 - val_loss: 0.0160\n",
      "Epoch 16/20\n",
      "149/149 - 11s - loss: 0.0079 - val_loss: 0.0161\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "149/149 - 11s - loss: 0.0078 - val_loss: 0.0161\n",
      "Epoch 18/20\n",
      "149/149 - 11s - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "149/149 - 11s - loss: 0.0076 - val_loss: 0.0161\n",
      "Epoch 20/20\n",
      "149/149 - 11s - loss: 0.0075 - val_loss: 0.0161\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 3\n",
      "2\n",
      "Epoch 1/20\n",
      "149/149 - 11s - loss: 0.2796 - val_loss: 0.0372\n",
      "Epoch 2/20\n",
      "149/149 - 11s - loss: 0.0266 - val_loss: 0.0231\n",
      "Epoch 3/20\n",
      "149/149 - 11s - loss: 0.0197 - val_loss: 0.0201\n",
      "Epoch 4/20\n",
      "149/149 - 11s - loss: 0.0177 - val_loss: 0.0175\n",
      "Epoch 5/20\n",
      "149/149 - 11s - loss: 0.0166 - val_loss: 0.0168\n",
      "Epoch 6/20\n",
      "149/149 - 11s - loss: 0.0158 - val_loss: 0.0162\n",
      "Epoch 7/20\n",
      "149/149 - 12s - loss: 0.0151 - val_loss: 0.0163\n",
      "Epoch 8/20\n",
      "149/149 - 12s - loss: 0.0143 - val_loss: 0.0156\n",
      "Epoch 9/20\n",
      "149/149 - 11s - loss: 0.0135 - val_loss: 0.0157\n",
      "Epoch 10/20\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "149/149 - 11s - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 11/20\n",
      "149/149 - 11s - loss: 0.0115 - val_loss: 0.0155\n",
      "Epoch 12/20\n",
      "149/149 - 11s - loss: 0.0106 - val_loss: 0.0156\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "149/149 - 11s - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 14/20\n",
      "149/149 - 11s - loss: 0.0092 - val_loss: 0.0157\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "149/149 - 11s - loss: 0.0088 - val_loss: 0.0157\n",
      "Epoch 16/20\n",
      "149/149 - 11s - loss: 0.0085 - val_loss: 0.0157\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "149/149 - 12s - loss: 0.0083 - val_loss: 0.0158\n",
      "Epoch 18/20\n",
      "149/149 - 11s - loss: 0.0082 - val_loss: 0.0158\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "149/149 - 11s - loss: 0.0081 - val_loss: 0.0158\n",
      "Epoch 20/20\n",
      "149/149 - 11s - loss: 0.0081 - val_loss: 0.0158\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 4\n",
      "3\n",
      "Epoch 1/20\n",
      "149/149 - 11s - loss: 0.2781 - val_loss: 0.0367\n",
      "Epoch 2/20\n",
      "149/149 - 11s - loss: 0.0268 - val_loss: 0.0229\n",
      "Epoch 3/20\n",
      "149/149 - 11s - loss: 0.0198 - val_loss: 0.0197\n",
      "Epoch 4/20\n",
      "149/149 - 11s - loss: 0.0177 - val_loss: 0.0177\n",
      "Epoch 5/20\n",
      "149/149 - 11s - loss: 0.0165 - val_loss: 0.0167\n",
      "Epoch 6/20\n",
      "149/149 - 11s - loss: 0.0157 - val_loss: 0.0163\n",
      "Epoch 7/20\n",
      "149/149 - 11s - loss: 0.0149 - val_loss: 0.0161\n",
      "Epoch 8/20\n",
      "149/149 - 11s - loss: 0.0142 - val_loss: 0.0166\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "149/149 - 11s - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 10/20\n",
      "149/149 - 11s - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 11/20\n",
      "149/149 - 11s - loss: 0.0116 - val_loss: 0.0158\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "149/149 - 11s - loss: 0.0109 - val_loss: 0.0159\n",
      "Epoch 13/20\n",
      "149/149 - 11s - loss: 0.0101 - val_loss: 0.0159\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "149/149 - 11s - loss: 0.0098 - val_loss: 0.0159\n",
      "Epoch 15/20\n",
      "149/149 - 11s - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "149/149 - 11s - loss: 0.0093 - val_loss: 0.0160\n",
      "Epoch 17/20\n",
      "149/149 - 11s - loss: 0.0091 - val_loss: 0.0160\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "149/149 - 11s - loss: 0.0091 - val_loss: 0.0160\n",
      "Epoch 19/20\n",
      "149/149 - 11s - loss: 0.0090 - val_loss: 0.0160\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "149/149 - 11s - loss: 0.0091 - val_loss: 0.0160\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Training fold 5\n",
      "4\n",
      "Epoch 1/20\n",
      "149/149 - 11s - loss: 0.2786 - val_loss: 0.0365\n",
      "Epoch 2/20\n",
      "149/149 - 11s - loss: 0.0269 - val_loss: 0.0226\n",
      "Epoch 3/20\n",
      "149/149 - 11s - loss: 0.0197 - val_loss: 0.0194\n",
      "Epoch 4/20\n",
      "149/149 - 11s - loss: 0.0176 - val_loss: 0.0174\n",
      "Epoch 5/20\n",
      "149/149 - 11s - loss: 0.0165 - val_loss: 0.0166\n",
      "Epoch 6/20\n",
      "149/149 - 11s - loss: 0.0157 - val_loss: 0.0162\n",
      "Epoch 7/20\n",
      "149/149 - 11s - loss: 0.0150 - val_loss: 0.0164\n",
      "Epoch 8/20\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "149/149 - 11s - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 9/20\n",
      "149/149 - 11s - loss: 0.0132 - val_loss: 0.0157\n",
      "Epoch 10/20\n",
      "149/149 - 11s - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 11/20\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "149/149 - 11s - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 12/20\n",
      "149/149 - 11s - loss: 0.0112 - val_loss: 0.0156\n",
      "Epoch 13/20\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "149/149 - 11s - loss: 0.0109 - val_loss: 0.0157\n",
      "Epoch 14/20\n",
      "149/149 - 11s - loss: 0.0105 - val_loss: 0.0157\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "149/149 - 11s - loss: 0.0104 - val_loss: 0.0157\n",
      "Epoch 16/20\n",
      "149/149 - 11s - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 17/20\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.0240000847261399e-05.\n",
      "149/149 - 11s - loss: 0.0102 - val_loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "149/149 - 11s - loss: 0.0102 - val_loss: 0.0157\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 4.09600033890456e-06.\n",
      "149/149 - 11s - loss: 0.0102 - val_loss: 0.0157\n",
      "Epoch 20/20\n",
      "149/149 - 11s - loss: 0.0102 - val_loss: 0.0157\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "oof_preds = []\n",
    "# seed everything\n",
    "seed_everything(SEED)\n",
    "for i in range(REPEATS):\n",
    "    m, oof = build_train(repeat_number = i, folds=FOLDS)\n",
    "    models = models + m\n",
    "    oof_preds.append(oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = train_targets_scored.columns[1:]\n",
    "N_TARGETS = len(target_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['5-alpha_reductase_inhibitor', '11-beta-hsd1_inhibitor',\n",
       "       'acat_inhibitor', 'acetylcholine_receptor_agonist',\n",
       "       'acetylcholine_receptor_antagonist', 'acetylcholinesterase_inhibitor',\n",
       "       'adenosine_receptor_agonist', 'adenosine_receptor_antagonist',\n",
       "       'adenylyl_cyclase_activator', 'adrenergic_receptor_agonist',\n",
       "       ...\n",
       "       'tropomyosin_receptor_kinase_inhibitor', 'trpv_agonist',\n",
       "       'trpv_antagonist', 'tubulin_inhibitor', 'tyrosine_kinase_inhibitor',\n",
       "       'ubiquitin_specific_protease_inhibitor', 'vegfr_inhibitor', 'vitamin_b',\n",
       "       'vitamin_d_receptor_agonist', 'wnt_inhibitor'],\n",
       "      dtype='object', length=206)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat 1 OOF Log Loss: 0.01567695950269504\n",
      "Mean OOF Log Loss: 0.01567695950269504\n"
     ]
    }
   ],
   "source": [
    "mean_oof_preds = y_train.copy()\n",
    "mean_oof_preds.loc[:, target_cols] = 0\n",
    "for i, p in enumerate(oof_preds):\n",
    "    print(f\"Repeat {i + 1} OOF Log Loss: {metric(y_train, p)}\")\n",
    "    mean_oof_preds.loc[:, target_cols] += p[target_cols]\n",
    "\n",
    "mean_oof_preds.loc[:, target_cols] /= len(oof_preds)\n",
    "print(f\"Mean OOF Log Loss: {metric(y_train, mean_oof_preds)}\")\n",
    "# mean_oof_preds.loc[train_feature['cp_type'] == 0, target_cols] = 0\n",
    "# print(f\"Mean OOF Log Loss (ctl adjusted): {metric(y_train, mean_oof_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = sub.copy()\n",
    "test_preds[target_cols] = 0\n",
    "for model in models:\n",
    "    test_preds.loc[:,target_cols] += model.predict(test)\n",
    "test_preds.loc[:,target_cols] /= len(models)\n",
    "# test_preds.loc[x_test['cp_type'] == 0, target_cols] = 0\n",
    "test_preds.to_csv('submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>g-0</th>\n",
       "      <th>g-1</th>\n",
       "      <th>g-2</th>\n",
       "      <th>g-3</th>\n",
       "      <th>g-4</th>\n",
       "      <th>g-5</th>\n",
       "      <th>g-6</th>\n",
       "      <th>g-7</th>\n",
       "      <th>g-8</th>\n",
       "      <th>g-9</th>\n",
       "      <th>...</th>\n",
       "      <th>c-95</th>\n",
       "      <th>c-96</th>\n",
       "      <th>c-97</th>\n",
       "      <th>c-98</th>\n",
       "      <th>c-99</th>\n",
       "      <th>cp_dose_0</th>\n",
       "      <th>cp_dose_1</th>\n",
       "      <th>cp_time_0</th>\n",
       "      <th>cp_time_1</th>\n",
       "      <th>cp_time_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.320196</td>\n",
       "      <td>0.544506</td>\n",
       "      <td>0.494816</td>\n",
       "      <td>0.402475</td>\n",
       "      <td>0.483780</td>\n",
       "      <td>0.569124</td>\n",
       "      <td>0.564588</td>\n",
       "      <td>0.660641</td>\n",
       "      <td>0.512204</td>\n",
       "      <td>0.695735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771086</td>\n",
       "      <td>0.742021</td>\n",
       "      <td>0.769870</td>\n",
       "      <td>0.774235</td>\n",
       "      <td>0.668236</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343589</td>\n",
       "      <td>0.553916</td>\n",
       "      <td>0.593975</td>\n",
       "      <td>0.346656</td>\n",
       "      <td>0.366779</td>\n",
       "      <td>0.559432</td>\n",
       "      <td>0.468355</td>\n",
       "      <td>0.672281</td>\n",
       "      <td>0.510785</td>\n",
       "      <td>0.573060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.738396</td>\n",
       "      <td>0.743125</td>\n",
       "      <td>0.736893</td>\n",
       "      <td>0.657387</td>\n",
       "      <td>0.671496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367318</td>\n",
       "      <td>0.519358</td>\n",
       "      <td>0.501866</td>\n",
       "      <td>0.383110</td>\n",
       "      <td>0.301240</td>\n",
       "      <td>0.592842</td>\n",
       "      <td>0.557376</td>\n",
       "      <td>0.625567</td>\n",
       "      <td>0.566231</td>\n",
       "      <td>0.603974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701264</td>\n",
       "      <td>0.804606</td>\n",
       "      <td>0.852368</td>\n",
       "      <td>0.800275</td>\n",
       "      <td>0.710308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.386502</td>\n",
       "      <td>0.550529</td>\n",
       "      <td>0.546426</td>\n",
       "      <td>0.401450</td>\n",
       "      <td>0.353320</td>\n",
       "      <td>0.509085</td>\n",
       "      <td>0.611539</td>\n",
       "      <td>0.634660</td>\n",
       "      <td>0.579049</td>\n",
       "      <td>0.584374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710122</td>\n",
       "      <td>0.800674</td>\n",
       "      <td>0.763657</td>\n",
       "      <td>0.805774</td>\n",
       "      <td>0.682296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.329730</td>\n",
       "      <td>0.414718</td>\n",
       "      <td>0.634583</td>\n",
       "      <td>0.387780</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.577676</td>\n",
       "      <td>0.606519</td>\n",
       "      <td>0.687423</td>\n",
       "      <td>0.543289</td>\n",
       "      <td>0.489167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865460</td>\n",
       "      <td>0.718534</td>\n",
       "      <td>0.732645</td>\n",
       "      <td>0.838464</td>\n",
       "      <td>0.857515</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>0.384845</td>\n",
       "      <td>0.479092</td>\n",
       "      <td>0.719832</td>\n",
       "      <td>0.336155</td>\n",
       "      <td>0.441365</td>\n",
       "      <td>0.672607</td>\n",
       "      <td>0.580627</td>\n",
       "      <td>0.605468</td>\n",
       "      <td>0.465982</td>\n",
       "      <td>0.613961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743008</td>\n",
       "      <td>0.646575</td>\n",
       "      <td>0.686475</td>\n",
       "      <td>0.730936</td>\n",
       "      <td>0.676566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>0.317443</td>\n",
       "      <td>0.508742</td>\n",
       "      <td>0.673291</td>\n",
       "      <td>0.396525</td>\n",
       "      <td>0.415975</td>\n",
       "      <td>0.596615</td>\n",
       "      <td>0.534028</td>\n",
       "      <td>0.645363</td>\n",
       "      <td>0.543310</td>\n",
       "      <td>0.699729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879741</td>\n",
       "      <td>0.759822</td>\n",
       "      <td>0.752167</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.717610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>0.329691</td>\n",
       "      <td>0.517966</td>\n",
       "      <td>0.539813</td>\n",
       "      <td>0.332335</td>\n",
       "      <td>0.390018</td>\n",
       "      <td>0.606359</td>\n",
       "      <td>0.575976</td>\n",
       "      <td>0.694765</td>\n",
       "      <td>0.531297</td>\n",
       "      <td>0.658632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816810</td>\n",
       "      <td>0.743880</td>\n",
       "      <td>0.819313</td>\n",
       "      <td>0.730646</td>\n",
       "      <td>0.713481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>0.284729</td>\n",
       "      <td>0.367669</td>\n",
       "      <td>0.501486</td>\n",
       "      <td>0.438430</td>\n",
       "      <td>0.307533</td>\n",
       "      <td>0.565866</td>\n",
       "      <td>0.556101</td>\n",
       "      <td>0.562141</td>\n",
       "      <td>0.583205</td>\n",
       "      <td>0.610135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790432</td>\n",
       "      <td>0.721081</td>\n",
       "      <td>0.813015</td>\n",
       "      <td>0.819388</td>\n",
       "      <td>0.720869</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>0.322027</td>\n",
       "      <td>0.559790</td>\n",
       "      <td>0.543321</td>\n",
       "      <td>0.372247</td>\n",
       "      <td>0.384202</td>\n",
       "      <td>0.628990</td>\n",
       "      <td>0.526602</td>\n",
       "      <td>0.671382</td>\n",
       "      <td>0.526865</td>\n",
       "      <td>0.588538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748861</td>\n",
       "      <td>0.703828</td>\n",
       "      <td>0.779612</td>\n",
       "      <td>0.752376</td>\n",
       "      <td>0.762622</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3982 rows Ã— 877 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           g-0       g-1       g-2       g-3       g-4       g-5       g-6  \\\n",
       "0     0.320196  0.544506  0.494816  0.402475  0.483780  0.569124  0.564588   \n",
       "1     0.343589  0.553916  0.593975  0.346656  0.366779  0.559432  0.468355   \n",
       "2     0.367318  0.519358  0.501866  0.383110  0.301240  0.592842  0.557376   \n",
       "3     0.386502  0.550529  0.546426  0.401450  0.353320  0.509085  0.611539   \n",
       "4     0.329730  0.414718  0.634583  0.387780  0.353265  0.577676  0.606519   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3977  0.384845  0.479092  0.719832  0.336155  0.441365  0.672607  0.580627   \n",
       "3978  0.317443  0.508742  0.673291  0.396525  0.415975  0.596615  0.534028   \n",
       "3979  0.329691  0.517966  0.539813  0.332335  0.390018  0.606359  0.575976   \n",
       "3980  0.284729  0.367669  0.501486  0.438430  0.307533  0.565866  0.556101   \n",
       "3981  0.322027  0.559790  0.543321  0.372247  0.384202  0.628990  0.526602   \n",
       "\n",
       "           g-7       g-8       g-9  ...      c-95      c-96      c-97  \\\n",
       "0     0.660641  0.512204  0.695735  ...  0.771086  0.742021  0.769870   \n",
       "1     0.672281  0.510785  0.573060  ...  0.738396  0.743125  0.736893   \n",
       "2     0.625567  0.566231  0.603974  ...  0.701264  0.804606  0.852368   \n",
       "3     0.634660  0.579049  0.584374  ...  0.710122  0.800674  0.763657   \n",
       "4     0.687423  0.543289  0.489167  ...  0.865460  0.718534  0.732645   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3977  0.605468  0.465982  0.613961  ...  0.743008  0.646575  0.686475   \n",
       "3978  0.645363  0.543310  0.699729  ...  0.879741  0.759822  0.752167   \n",
       "3979  0.694765  0.531297  0.658632  ...  0.816810  0.743880  0.819313   \n",
       "3980  0.562141  0.583205  0.610135  ...  0.790432  0.721081  0.813015   \n",
       "3981  0.671382  0.526865  0.588538  ...  0.748861  0.703828  0.779612   \n",
       "\n",
       "          c-98      c-99  cp_dose_0  cp_dose_1  cp_time_0  cp_time_1  \\\n",
       "0     0.774235  0.668236        1.0        0.0        1.0        0.0   \n",
       "1     0.657387  0.671496        1.0        0.0        0.0        0.0   \n",
       "2     0.800275  0.710308        1.0        0.0        1.0        0.0   \n",
       "3     0.805774  0.682296        0.0        1.0        1.0        0.0   \n",
       "4     0.838464  0.857515        1.0        0.0        0.0        1.0   \n",
       "...        ...       ...        ...        ...        ...        ...   \n",
       "3977  0.730936  0.676566        1.0        0.0        1.0        0.0   \n",
       "3978  0.761719  0.717610        1.0        0.0        1.0        0.0   \n",
       "3979  0.730646  0.713481        1.0        0.0        0.0        0.0   \n",
       "3980  0.819388  0.720869        0.0        1.0        0.0        1.0   \n",
       "3981  0.752376  0.762622        1.0        0.0        0.0        0.0   \n",
       "\n",
       "      cp_time_2  \n",
       "0           0.0  \n",
       "1           1.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "3977        0.0  \n",
       "3978        0.0  \n",
       "3979        1.0  \n",
       "3980        0.0  \n",
       "3981        1.0  \n",
       "\n",
       "[3982 rows x 877 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kratagya/Desktop/ML_AI/python files/MOA prediction'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
