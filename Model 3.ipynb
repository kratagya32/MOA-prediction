{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.decomposition import PCA\n",
    " \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    " \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (23814, 876)\n",
      "train_targets_scored: (23814, 207)\n",
      "train_targets_nonscored: (23814, 403)\n",
      "train_drug: (23814, 2)\n",
      "test_features: (3982, 876)\n",
      "sample_submission: (3982, 207)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_features = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_features.csv\")\n",
    "test_features = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/test_features.csv\")\n",
    "train_targets_scored = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_targets_scored.csv\")\n",
    "train_targets_nonscored = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_targets_nonscored.csv\")\n",
    "sub = pd.read_csv('../../Data/Mechanisms of Action (MoA) Prediction/sample_submission.csv')\n",
    "#data = train_feature.append(test_feature)\n",
    "train_drug = pd.read_csv(\"../../Data/Mechanisms of Action (MoA) Prediction/train_drug.csv\")\n",
    "\n",
    "print(f'train_features: {train_features.shape}')\n",
    "print(f'train_targets_scored: {train_targets_scored.shape}')\n",
    "print(f'train_targets_nonscored: {train_targets_nonscored.shape}')\n",
    "print(f'train_drug: {train_drug.shape}')\n",
    "print(f'test_features: {test_features.shape}')\n",
    "print(f'sample_submission: {sub.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENES: ['g-0', 'g-1', 'g-2', 'g-3', 'g-4', 'g-5', 'g-6', 'g-7', 'g-8', 'g-9']\n",
      "CELLS: ['c-0', 'c-1', 'c-2', 'c-3', 'c-4', 'c-5', 'c-6', 'c-7', 'c-8', 'c-9']\n"
     ]
    }
   ],
   "source": [
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "\n",
    "print(f'GENES: {GENES[:10]}')\n",
    "print(f'CELLS: {CELLS[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e9c565be894edb87ec7c749d7400bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=872.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(GENES+CELLS):\n",
    "    transformer = QuantileTransformer(n_quantiles=250, random_state=0,\n",
    "                                      output_distribution='normal')\n",
    "    vec_len_train = len(train_features[col].values)\n",
    "    vec_len_test = len(test_features[col].values)\n",
    "    input_vec_train = train_features[col].values.reshape(vec_len_train,1)\n",
    "    input_vec_test = test_features[col].values.reshape(vec_len_test,1)\n",
    "    transformer.fit(input_vec_train)\n",
    "    train_features[col] = transformer.transform(input_vec_train).reshape(1,vec_len_train)[0]\n",
    "    test_features[col] = transformer.transform(input_vec_test).reshape(1,vec_len_test)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_VALUE = 42\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=SEED_VALUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA features + Existing features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (23814, 1476)\n",
      "test_features: (3982, 1476)\n"
     ]
    }
   ],
   "source": [
    "# GENES\n",
    "n_comp = 600\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[GENES]), pd.DataFrame(test_features[GENES])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=SEED_VALUE).fit_transform(data[GENES]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_G-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(GENES))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "print('train_features: {}'.format(train_features.shape))\n",
    "print('test_features: {}'.format(test_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (23814, 1526)\n",
      "test_features: (3982, 1526)\n"
     ]
    }
   ],
   "source": [
    "# CELLS\n",
    "n_comp = 50\n",
    "\n",
    "data = pd.concat([pd.DataFrame(train_features[CELLS]), pd.DataFrame(test_features[CELLS])])\n",
    "data2 = (PCA(n_components=n_comp, random_state=SEED_VALUE).fit_transform(data[CELLS]))\n",
    "train2 = data2[:train_features.shape[0]]; test2 = data2[-test_features.shape[0]:]\n",
    "\n",
    "train2 = pd.DataFrame(train2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "test2 = pd.DataFrame(test2, columns=[f'pca_C-{i}' for i in range(n_comp)])\n",
    "\n",
    "# drop_cols = [f'c-{i}' for i in range(n_comp,len(CELLS))]\n",
    "train_features = pd.concat((train_features, train2), axis=1)\n",
    "test_features = pd.concat((test_features, test2), axis=1)\n",
    "\n",
    "print(f'train_features: {train_features.shape}')\n",
    "print(f'test_features: {test_features.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature Selection using Variance Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "thresold = 0.8\n",
    "var_thres = VarianceThreshold(thresold)\n",
    "data = train_features.append(test_features)\n",
    "data_transformed = var_thres.fit_transform(data.iloc[:,4:])\n",
    "\n",
    "train_feature_transformed = data_transformed[:train_features.shape[0]]\n",
    "test_feature_transformed = data_transformed[-test_features.shape[0]:]\n",
    "\n",
    "\n",
    "train_features = pd.DataFrame(train_features[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "                             .values.reshape(-1, 4),columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "train_features = pd.concat([train_features, pd.DataFrame(train_feature_transformed)]\n",
    "                          , axis=1)\n",
    "\n",
    "test_features = pd.DataFrame(test_features[['sig_id','cp_type','cp_time','cp_dose']]\n",
    "                            .values.reshape(-1, 4),columns=['sig_id','cp_type','cp_time','cp_dose'])\n",
    "\n",
    "test_features = pd.concat([test_features, pd.DataFrame(test_feature_transformed)]\n",
    "                          , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_features: (23814, 1047)\n",
      "test_features: (3982, 1047)\n"
     ]
    }
   ],
   "source": [
    "print('train_features: {}'.format(train_features.shape))\n",
    "print('test_features: {}'.format(test_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_type</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1033</th>\n",
       "      <th>1034</th>\n",
       "      <th>1035</th>\n",
       "      <th>1036</th>\n",
       "      <th>1037</th>\n",
       "      <th>1038</th>\n",
       "      <th>1039</th>\n",
       "      <th>1040</th>\n",
       "      <th>1041</th>\n",
       "      <th>1042</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134720</td>\n",
       "      <td>0.907903</td>\n",
       "      <td>-0.416118</td>\n",
       "      <td>-0.967674</td>\n",
       "      <td>-0.254345</td>\n",
       "      <td>-1.015619</td>\n",
       "      <td>...</td>\n",
       "      <td>4.862863</td>\n",
       "      <td>1.559229</td>\n",
       "      <td>-1.534285</td>\n",
       "      <td>1.177716</td>\n",
       "      <td>0.925370</td>\n",
       "      <td>1.068808</td>\n",
       "      <td>-0.157433</td>\n",
       "      <td>0.261104</td>\n",
       "      <td>-0.169199</td>\n",
       "      <td>-0.356049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119153</td>\n",
       "      <td>0.681745</td>\n",
       "      <td>0.271864</td>\n",
       "      <td>0.080060</td>\n",
       "      <td>1.204035</td>\n",
       "      <td>0.685604</td>\n",
       "      <td>...</td>\n",
       "      <td>5.029348</td>\n",
       "      <td>-0.346043</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.987392</td>\n",
       "      <td>-0.520358</td>\n",
       "      <td>-0.662947</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>0.437961</td>\n",
       "      <td>-1.148621</td>\n",
       "      <td>-0.574124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779597</td>\n",
       "      <td>0.945550</td>\n",
       "      <td>1.426347</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>-0.006571</td>\n",
       "      <td>1.493254</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.417928</td>\n",
       "      <td>0.298660</td>\n",
       "      <td>-0.308681</td>\n",
       "      <td>-0.234492</td>\n",
       "      <td>-0.124479</td>\n",
       "      <td>0.707067</td>\n",
       "      <td>0.881464</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>-1.048427</td>\n",
       "      <td>-0.499332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734783</td>\n",
       "      <td>-0.274535</td>\n",
       "      <td>-0.438344</td>\n",
       "      <td>0.758889</td>\n",
       "      <td>2.443212</td>\n",
       "      <td>-0.859239</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.007538</td>\n",
       "      <td>1.143655</td>\n",
       "      <td>-1.001306</td>\n",
       "      <td>-1.577082</td>\n",
       "      <td>0.026714</td>\n",
       "      <td>1.233747</td>\n",
       "      <td>-0.391159</td>\n",
       "      <td>0.306862</td>\n",
       "      <td>-0.322912</td>\n",
       "      <td>-1.178304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>trt_cp</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452759</td>\n",
       "      <td>-0.476195</td>\n",
       "      <td>0.973323</td>\n",
       "      <td>0.972162</td>\n",
       "      <td>1.464377</td>\n",
       "      <td>-0.870973</td>\n",
       "      <td>...</td>\n",
       "      <td>3.579749</td>\n",
       "      <td>0.577848</td>\n",
       "      <td>-0.662529</td>\n",
       "      <td>-0.305409</td>\n",
       "      <td>0.241229</td>\n",
       "      <td>-0.187152</td>\n",
       "      <td>0.340585</td>\n",
       "      <td>-0.046619</td>\n",
       "      <td>-0.505215</td>\n",
       "      <td>0.234645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1047 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_type cp_time cp_dose         0         1         2  \\\n",
       "0  id_000644bb2  trt_cp      24      D1  1.134720  0.907903 -0.416118   \n",
       "1  id_000779bfc  trt_cp      72      D1  0.119153  0.681745  0.271864   \n",
       "2  id_000a6266a  trt_cp      48      D1  0.779597  0.945550  1.426347   \n",
       "3  id_0015fd391  trt_cp      48      D1 -0.734783 -0.274535 -0.438344   \n",
       "4  id_001626bd3  trt_cp      72      D2 -0.452759 -0.476195  0.973323   \n",
       "\n",
       "          3         4         5  ...       1033      1034      1035      1036  \\\n",
       "0 -0.967674 -0.254345 -1.015619  ...   4.862863  1.559229 -1.534285  1.177716   \n",
       "1  0.080060  1.204035  0.685604  ...   5.029348 -0.346043  0.026703  0.987392   \n",
       "2 -0.132164 -0.006571  1.493254  ...  -1.417928  0.298660 -0.308681 -0.234492   \n",
       "3  0.758889  2.443212 -0.859239  ... -11.007538  1.143655 -1.001306 -1.577082   \n",
       "4  0.972162  1.464377 -0.870973  ...   3.579749  0.577848 -0.662529 -0.305409   \n",
       "\n",
       "       1037      1038      1039      1040      1041      1042  \n",
       "0  0.925370  1.068808 -0.157433  0.261104 -0.169199 -0.356049  \n",
       "1 -0.520358 -0.662947 -0.266200  0.437961 -1.148621 -0.574124  \n",
       "2 -0.124479  0.707067  0.881464  0.004502 -1.048427 -0.499332  \n",
       "3  0.026714  1.233747 -0.391159  0.306862 -0.322912 -1.178304  \n",
       "4  0.241229 -0.187152  0.340585 -0.046619 -0.505215  0.234645  \n",
       "\n",
       "[5 rows x 1047 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>drug_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>b68db1d53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>df89a8e5a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>18bb41b2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>8c7f86626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>7cbed3131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id    drug_id\n",
       "0  id_000644bb2  b68db1d53\n",
       "1  id_000779bfc  df89a8e5a\n",
       "2  id_000a6266a  18bb41b2c\n",
       "3  id_0015fd391  8c7f86626\n",
       "4  id_001626bd3  7cbed3131"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_drug.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_nonscored, on='sig_id')\n",
    "train = train.merge(train_drug, on='sig_id')\n",
    "train = train[train['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type'] != 'ctl_vehicle'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('cp_type', inplace=True, axis=1)\n",
    "test.drop('cp_type', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_targets: 206\n",
      "num_aux_targets: 402\n",
      "num_all_targets: 608\n"
     ]
    }
   ],
   "source": [
    "target_cols = [x for x in train_targets_scored.columns if x!='sig_id']\n",
    "aux_target_cols = [x for x in train_targets_nonscored.columns if x!='sig_id']\n",
    "all_target_cols = target_cols + aux_target_cols\n",
    "\n",
    "num_targets = len(target_cols)\n",
    "num_aux_targets = len(aux_target_cols)\n",
    "num_all_targets = len(all_target_cols)\n",
    "\n",
    "print(f\"num_targets: {num_targets}\")\n",
    "print(f\"num_aux_targets: {num_aux_targets}\")\n",
    "print(f\"num_all_targets: {num_all_targets}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1655)\n",
      "(3624, 1046)\n",
      "(3982, 207)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(sub.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoADataset:\n",
    "    def __init__(self,features,targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx,:], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx,:], dtype=torch.float)\n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset:\n",
    "    def __init__(self,features):\n",
    "        self.features = features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx,:], dtype=torch.float)   \n",
    "        }\n",
    "        return dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "#   model.train() tells your model that you are training the model\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "    \n",
    "    for data in dataloader:\n",
    "#       Sets gradients of all model parameters to zero\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(ouputs,targets)\n",
    "#       loss.backward() computes dloss/dx for every parameter x which has requires_grad=True\n",
    "        loss.backward()\n",
    "#       optimizer.step updates the value of x using the gradient x.grad \n",
    "        optimizer.step()\n",
    "#       If you don’t call it, the learning rate won’t be changed and stays at the initial value\n",
    "        scheduler.step()\n",
    "    \n",
    "        final_loss += loss.item()\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    return final_loss\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(ouputs,targets)\n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "    return final_loss, valid_preds\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "        \n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "        \n",
    "    preds = np.concatenate(preds)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight = None, reduction = 'mean', smoothing = 0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    @staticmethod\n",
    "    def _smoothing(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets*(1-smoothing) + 0.5*smoothing\n",
    "            \n",
    "        return targets\n",
    "    \n",
    "    def forward(self,inputs,targets):\n",
    "        targets = Smooy=thBCEwLogits._smoothing(targets, inputs.size(-1),\n",
    "                                                self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight)\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            loss=loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            loss=loss.sum()\n",
    "            \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets):\n",
    "        super(Model,self).__init__()\n",
    "        self.hidden_size = [1500, 1250, 1000, 750]\n",
    "        self.dropout_values = [0.5, 0.35, 0.30, 0.25]\n",
    "        \n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dense1 = nn.Linear(num_features, self.hidden_size[0])\n",
    "        \n",
    "        self.batch_norm2 = nn.BatchNorm1d(self.hidden_size[0])\n",
    "        self.dropout2 = nn.Dropout(self.dropout_values[0])\n",
    "        self.dense2 = nn.Linear(self.hidden_size[0], self.hidden_size[1])\n",
    "        \n",
    "        self.batch_norm3 = nn.BatchNorm1d(self.hidden_size[1])\n",
    "        self.dropout3 = nn.Dropout(self.dropout_values[1])\n",
    "        self.dense3 = nn.Linear(self.hidden_size[1], self.hidden_size[2])\n",
    "        \n",
    "        self.batch_norm4 = nn.BatchNorm1d(self.hidden_size[2])\n",
    "        self.dropout4 = nn.Dropout(self.dropout_values[2])\n",
    "        self.dense4 = nn.Linear(self.hidden_size[2], self.hidden_size[3])\n",
    "        \n",
    "        self.batch_norm5 = nn.BatchNorm1d(self.hidden_size[3])\n",
    "        self.dropout5 = nn.Dropout(self.dropout_values[3])\n",
    "        self.dense5 = nn.utils.weight_norm(nn.Linear(self.hidden_size[3], num_targets))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.leaky_relu(self.dense1(x))\n",
    "        \n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.leaky_relu(self.dense2(x))\n",
    "        \n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = F.leaky_relu(self.dense3(x))\n",
    "        \n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.dropout4(x)\n",
    "        x = F.leaky_relu(self.dense4(x))\n",
    "        \n",
    "        x = self.batch_norm5(x)\n",
    "        x = self.dropout5(x)\n",
    "        x = self.dense5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self,pred,target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "            \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTuneScheduler:\n",
    "    def __init__(self, epochs):\n",
    "        self.epochs = epochs\n",
    "        self.epochs_per_step = 0\n",
    "        self.frozen_layers = []\n",
    "\n",
    "    def copy_without_top(self, model, num_features, num_targets, num_targets_new):\n",
    "        self.frozen_layers = []\n",
    "\n",
    "        model_new = Model(num_features, num_targets)\n",
    "        model_new.load_state_dict(model.state_dict())\n",
    "\n",
    "        # Freeze all weights\n",
    "        for name, param in model_new.named_parameters():\n",
    "            layer_index = name.split('.')[0][-1]\n",
    "\n",
    "            if layer_index == 5:\n",
    "                continue\n",
    "\n",
    "            param.requires_grad = False\n",
    "\n",
    "            # Save frozen layer names\n",
    "            if layer_index not in self.frozen_layers:\n",
    "                self.frozen_layers.append(layer_index)\n",
    "\n",
    "        self.epochs_per_step = self.epochs // len(self.frozen_layers)\n",
    "\n",
    "        # Replace the top layers with another ones\n",
    "        model_new.batch_norm5 = nn.BatchNorm1d(model_new.hidden_size[3])\n",
    "        model_new.dropout5 = nn.Dropout(model_new.dropout_value[3])\n",
    "        model_new.dense5 = nn.utils.weight_norm(nn.Linear(model_new.hidden_size[-1], num_targets_new))\n",
    "        model_new.to(DEVICE)\n",
    "        return model_new\n",
    "\n",
    "    def step(self, epoch, model):\n",
    "        if len(self.frozen_layers) == 0:\n",
    "            return\n",
    "\n",
    "        if epoch % self.epochs_per_step == 0:\n",
    "            last_frozen_index = self.frozen_layers[-1]\n",
    "            \n",
    "            # Unfreeze parameters of the last frozen layer\n",
    "            for name, param in model.named_parameters():\n",
    "                layer_index = name.split('.')[0][-1]\n",
    "\n",
    "                if layer_index == last_frozen_index:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            del self.frozen_layers[-1]  # Remove the last layer as unfrozen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    data = pd.get_dummies(data, columns=['cp_time','cp_dose'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in process_data(train).columns if c not in all_target_cols]\n",
    "feature_cols = [c for c in feature_cols if c not in ['kfold', 'sig_id', 'drug_id']]\n",
    "num_features = len(feature_cols)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 24\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "WEIGHT_DECAY = {'ALL_TARGETS': 1e-5, 'SCORED_ONLY': 3e-6}\n",
    "MAX_LR = {'ALL_TARGETS': 1e-2, 'SCORED_ONLY': 3e-3}\n",
    "DIV_FACTOR = {'ALL_TARGETS': 1e3, 'SCORED_ONLY': 1e2}\n",
    "PCT_START = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (batch_norm1): BatchNorm1d(1048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dense1): Linear(in_features=1048, out_features=1500, bias=True)\n",
       "  (batch_norm2): BatchNorm1d(1500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       "  (dense2): Linear(in_features=1500, out_features=1250, bias=True)\n",
       "  (batch_norm3): BatchNorm1d(1250, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout3): Dropout(p=0.35, inplace=False)\n",
       "  (dense3): Linear(in_features=1250, out_features=1000, bias=True)\n",
       "  (batch_norm4): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout4): Dropout(p=0.3, inplace=False)\n",
       "  (dense4): Linear(in_features=1000, out_features=750, bias=True)\n",
       "  (batch_norm5): BatchNorm1d(750, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout5): Dropout(p=0.25, inplace=False)\n",
       "  (dense5): Linear(in_features=750, out_features=608, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(num_features, num_all_targets)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87d714366    718\n",
       "9f80f3f77    246\n",
       "8b87a7a83    203\n",
       "5628cb3ee    202\n",
       "d08af5d4b    196\n",
       "            ... \n",
       "d75904698      1\n",
       "225385f09      1\n",
       "d70cdde82      1\n",
       "fe6105bde      1\n",
       "ede646bcc      1\n",
       "Name: drug_id, Length: 3288, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drug_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>cp_time</th>\n",
       "      <th>cp_dose</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>xanthine_oxidase_inhibitor</th>\n",
       "      <th>xiap_inhibitor</th>\n",
       "      <th>drug_id</th>\n",
       "      <th>kfold_0</th>\n",
       "      <th>kfold_1</th>\n",
       "      <th>kfold_2</th>\n",
       "      <th>kfold_3</th>\n",
       "      <th>kfold_4</th>\n",
       "      <th>kfold_5</th>\n",
       "      <th>kfold_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_000644bb2</td>\n",
       "      <td>24</td>\n",
       "      <td>D1</td>\n",
       "      <td>1.134720</td>\n",
       "      <td>0.907903</td>\n",
       "      <td>-0.416118</td>\n",
       "      <td>-0.967674</td>\n",
       "      <td>-0.254345</td>\n",
       "      <td>-1.015619</td>\n",
       "      <td>-1.365433</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b68db1d53</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_000779bfc</td>\n",
       "      <td>72</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.119153</td>\n",
       "      <td>0.681745</td>\n",
       "      <td>0.271864</td>\n",
       "      <td>0.080060</td>\n",
       "      <td>1.204035</td>\n",
       "      <td>0.685604</td>\n",
       "      <td>0.314377</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>df89a8e5a</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_000a6266a</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>0.779597</td>\n",
       "      <td>0.945550</td>\n",
       "      <td>1.426347</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>-0.006571</td>\n",
       "      <td>1.493254</td>\n",
       "      <td>0.235191</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18bb41b2c</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_0015fd391</td>\n",
       "      <td>48</td>\n",
       "      <td>D1</td>\n",
       "      <td>-0.734783</td>\n",
       "      <td>-0.274535</td>\n",
       "      <td>-0.438344</td>\n",
       "      <td>0.758889</td>\n",
       "      <td>2.443212</td>\n",
       "      <td>-0.859239</td>\n",
       "      <td>-2.302712</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8c7f86626</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_001626bd3</td>\n",
       "      <td>72</td>\n",
       "      <td>D2</td>\n",
       "      <td>-0.452759</td>\n",
       "      <td>-0.476195</td>\n",
       "      <td>0.973323</td>\n",
       "      <td>0.972162</td>\n",
       "      <td>1.464377</td>\n",
       "      <td>-0.870973</td>\n",
       "      <td>-0.375387</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7cbed3131</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1662 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id cp_time cp_dose         0         1         2         3  \\\n",
       "0  id_000644bb2      24      D1  1.134720  0.907903 -0.416118 -0.967674   \n",
       "1  id_000779bfc      72      D1  0.119153  0.681745  0.271864  0.080060   \n",
       "2  id_000a6266a      48      D1  0.779597  0.945550  1.426347 -0.132164   \n",
       "3  id_0015fd391      48      D1 -0.734783 -0.274535 -0.438344  0.758889   \n",
       "4  id_001626bd3      72      D2 -0.452759 -0.476195  0.973323  0.972162   \n",
       "\n",
       "          4         5         6  ...  xanthine_oxidase_inhibitor  \\\n",
       "0 -0.254345 -1.015619 -1.365433  ...                           0   \n",
       "1  1.204035  0.685604  0.314377  ...                           0   \n",
       "2 -0.006571  1.493254  0.235191  ...                           0   \n",
       "3  2.443212 -0.859239 -2.302712  ...                           0   \n",
       "4  1.464377 -0.870973 -0.375387  ...                           0   \n",
       "\n",
       "   xiap_inhibitor    drug_id  kfold_0  kfold_1  kfold_2  kfold_3  kfold_4  \\\n",
       "0               0  b68db1d53        1        3        3        5        0   \n",
       "1               0  df89a8e5a        0        3        6        3        3   \n",
       "2               0  18bb41b2c        5        3        3        1        3   \n",
       "3               0  8c7f86626        4        3        1        2        4   \n",
       "4               0  7cbed3131        6        5        3        3        2   \n",
       "\n",
       "   kfold_5  kfold_6  \n",
       "0        5        2  \n",
       "1        4        1  \n",
       "2        0        4  \n",
       "3        5        2  \n",
       "4        1        4  \n",
       "\n",
       "[5 rows x 1662 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def make_cv_folds(train, SEEDS, NFOLDS, DRUG_THRESH):\n",
    "    vc = train.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= DRUG_THRESH].index.sort_values()\n",
    "    vc2 = vc.loc[vc > DRUG_THRESH].index.sort_values()\n",
    "\n",
    "    for seed_id in range(SEEDS):\n",
    "        kfold_col = 'kfold_{}'.format(seed_id)\n",
    "        \n",
    "        # STRATIFY DRUGS 18X OR LESS\n",
    "        dct1 = {}\n",
    "        dct2 = {}\n",
    "\n",
    "        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n",
    "        tmp = train.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "\n",
    "        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n",
    "            dd = {k: fold for k in tmp.index[idxV].values}\n",
    "            dct1.update(dd)\n",
    "\n",
    "        # STRATIFY DRUGS MORE THAN 18X\n",
    "        skf = MultilabelStratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=seed_id)\n",
    "        tmp = train.loc[train.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "\n",
    "        for fold,(idxT, idxV) in enumerate(skf.split(tmp, tmp[target_cols])):\n",
    "            dd = {k: fold for k in tmp.sig_id[idxV].values}\n",
    "            dct2.update(dd)\n",
    "\n",
    "        # ASSIGN FOLDS\n",
    "        train[kfold_col] = train.drug_id.map(dct1)\n",
    "        train.loc[train[kfold_col].isna(), kfold_col] = train.loc[train[kfold_col].isna(), 'sig_id'].map(dct2)\n",
    "        train[kfold_col] = train[kfold_col].astype('int8')\n",
    "        \n",
    "    return train\n",
    "\n",
    "SEEDS = 7\n",
    "NFOLDS = 7\n",
    "DRUG_THRESH = 18\n",
    "\n",
    "train = make_cv_folds(train, SEEDS, NFOLDS, DRUG_THRESH)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold_id, seed_id):\n",
    "    seed_everything(seed_id)\n",
    "    \n",
    "    train_ = process_data(train)\n",
    "    test_ = process_data(test)\n",
    "    \n",
    "    kfold_col = f'kfold_{seed_id}'\n",
    "    trn_idx = train_[train_[kfold_col] != fold_id].index\n",
    "    val_idx = train_[train_[kfold_col] == fold_id].index\n",
    "    \n",
    "    train_df = train_[train_[kfold_col] != fold_id].reset_index(drop=True)\n",
    "    valid_df = train_[train_[kfold_col] == fold_id].reset_index(drop=True)\n",
    "    \n",
    "    def train_model(model, tag_name, target_cols_now, fine_tune_scheduler=None):\n",
    "        x_train, y_train  = train_df[feature_cols].values, train_df[target_cols_now].values\n",
    "        x_valid, y_valid =  valid_df[feature_cols].values, valid_df[target_cols_now].values\n",
    "        \n",
    "        train_dataset = MoADataset(x_train, y_train)\n",
    "        valid_dataset = MoADataset(x_valid, y_valid)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=WEIGHT_DECAY[tag_name])\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                  steps_per_epoch=len(trainloader),\n",
    "                                                  pct_start=PCT_START,\n",
    "                                                  div_factor=DIV_FACTOR[tag_name], \n",
    "                                                  max_lr=MAX_LR[tag_name],\n",
    "                                                  epochs=EPOCHS)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        loss_tr = SmoothBCEwLogits(smoothing=0.001)\n",
    "\n",
    "        oof = np.zeros((len(train), len(target_cols_now)))\n",
    "        best_loss = np.inf\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            if fine_tune_scheduler is not None:\n",
    "                fine_tune_scheduler.step(epoch, model)\n",
    "\n",
    "            train_loss = train_fn(model, optimizer, scheduler, loss_tr, trainloader, DEVICE)\n",
    "            valid_loss, valid_preds = valid_fn(model, loss_fn, validloader, DEVICE)\n",
    "            print(f\"SEED: {seed_id}, FOLD: {fold_id}, {tag_name}, EPOCH: {epoch}, train_loss: {train_loss:.6f}, valid_loss: {valid_loss:.6f}\")\n",
    "\n",
    "            if np.isnan(valid_loss):\n",
    "                break\n",
    "            \n",
    "            if valid_loss < best_loss:\n",
    "                best_loss = valid_loss\n",
    "                oof[val_idx] = valid_preds\n",
    "                torch.save(model.state_dict(), f\"{tag_name}_FOLD{fold_id}_.pth\")\n",
    "\n",
    "        return oof\n",
    "\n",
    "    fine_tune_scheduler = FineTuneScheduler(EPOCHS)\n",
    "\n",
    "    pretrained_model = Model(num_features, num_all_targets)\n",
    "    pretrained_model.to(DEVICE)\n",
    "\n",
    "    # Train on scored + nonscored targets\n",
    "    train_model(pretrained_model, 'ALL_TARGETS', all_target_cols)\n",
    "\n",
    "    # Load the pretrained model with the best loss\n",
    "    pretrained_model = Model(num_features, num_all_targets)\n",
    "    pretrained_model.load_state_dict(torch.load(f\"ALL_TARGETS_FOLD{fold_id}_.pth\"))\n",
    "    pretrained_model.to(DEVICE)\n",
    "\n",
    "    # Copy model without the top layer\n",
    "    final_model = fine_tune_scheduler.copy_without_top(pretrained_model, num_features, num_all_targets, num_targets)\n",
    "\n",
    "    # Fine-tune the model on scored targets only\n",
    "    oof = train_model(final_model, 'SCORED_ONLY', target_cols, fine_tune_scheduler)\n",
    "\n",
    "    # Load the fine-tuned model with the best loss\n",
    "    model = Model(num_features, num_targets)\n",
    "    model.load_state_dict(torch.load(f\"SCORED_ONLY_FOLD{fold_id}_.pth\"))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    x_test = test_[feature_cols].values\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    predictions = np.zeros((len(test_), num_targets))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed_id):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    \n",
    "    for fold_id in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold_id, seed_id)\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "        \n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# Averaging on multiple SEEDS\n",
    "SEED = [0, 1, 2, 3, 4, 5, 6]\n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "time_begin = time()\n",
    "\n",
    "for seed_id in SEED:\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed_id)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "\n",
    "time_diff = time() - time_begin\n",
    "\n",
    "train[target_cols] = oof\n",
    "test[target_cols] = predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
